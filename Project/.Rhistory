install.packages("maps")
suppressWarnings(require(maps))
us = map_data("state")
map.simple = ggplot(dummyDF, aes(map_id = state))
map.simple = map.simple + geom_map(map = us, fill = "white" + "Black")
map.simple = map.simple + geom_map(map = us, fill = "white", + "Black")
map.simple = map.simple + geom_map(map = us, fill = "white")
map.simple = map.simple + geom_map(map = us, fill = "white") +
expand_limits(x = us$long, y = us$lat) + coord_map() + ggtitle("USA!")
map.simple
map.simple = map.simple + geom_map(map = us, fill = "white") +
expand_limits(x = us$long, y = us$lat) + coord_map() + ggtitle("USA!")
map.simple = ggplot(dummyDF, aes(map_id = state))
map.simple = map.simple + geom_map(map = us, fill = "white") +
expand_limits(x = us$long, y = us$lat) + coord_map() + ggtitle("USA!")
map.simple
install.packages("evaluate")
map.simple
suppressWarnings(require(evaluate))
map.simple
rm(list=ls()) # clear work space
suppressWarnings(require(ggplot2))
suppressWarnings(require(maps))
suppressWarnings(require(evaluate))
dummyDF = data.frame(state.name, stringsAsFactors = FALSE)
dummyDF$state = tolower(dummyDF$state)
us = map_data("state")
map.simple = ggplot(dummyDF, aes(map_id = state))
map.simple = map.simple + geom_map(map = us, fill = "white") +
expand_limits(x = us$long, y = us$lat) + coord_map() + ggtitle("USA!")
map.simple
install.packages("mapproj")
suppressWarnings(require(mapproj))
map.simple = map.simple + geom_map(map = us, fill = "white") +
expand_limits(x = us$long, y = us$lat) + coord_map() + ggtitle("USA!")
map.simple = ggplot(dummyDF, aes(map_id = state))
map.simple = map.simple + geom_map(map = us, fill = "white") +
expand_limits(x = us$long, y = us$lat) + coord_map() + ggtitle("USA!")
map.simple
map.simple = ggplot(dummyDF, aes(map_id = state)) +
map.simple + geom_map(map = us, fill = "white", + color = "black") +
expand_limits(x = us$long, y = us$lat) + coord_map() + ggtitle("USA!")
map.simple = ggplot(dummyDF, aes(map_id = state)) +
map.simple + geom_map(map = us, fill = "white", + color = "black") +
expand_limits(x = us$long, y = us$lat) + coord_map() + ggtitle("USA!")
map.simple = ggplot(dummyDF, aes(map_id = state)) +
geom_map(map = us, fill = "white", + color = "black") +
expand_limits(x = us$long, y = us$lat) + coord_map() + ggtitle("USA!")
map.simple = ggplot(dummyDF, aes(map_id = state)) +
geom_map(map = us, fill = "white",  color = "black") +
expand_limits(x = us$long, y = us$lat) + coord_map() + ggtitle("USA!")
map.simple
map.simple + geom_point(aes(-100, 30))
readStates = function() {
# read from url
states = read.csv(url("http://www2.census.gov/programs-surveys/popest/tables/2010-2011/state/totals/nst-est2011-01.csv"))
states = states[ , colSums(is.na(states)) < nrow(states)] # remove na cols
states = states[complete.cases(states),] # remove na rows
colnames(states) = c('stateName', 'base2010', 'base2011', 'Jul2010', 'Jul2011') # name cols
states = states[9:59 , ] # Only want 50 states plus DC... FU Puerto Rico
# turning those factors into numeric
states$base2010 = as.numeric(gsub(",","",states$base2010))
states$base2011 = as.numeric(gsub(",","",states$base2011))
states$Jul2010 = as.numeric(gsub(",","",states$Jul2010))
states$Jul2011 = as.numeric(gsub(",","",states$Jul2011))
return (states)
}
dfStates = readStates()
map.simple + geom_point(aes(25, 80))
map.simple = ggplot(dummyDF, aes(map_id = state)) +
geom_map(map = us, fill = "white",  color = "black") +
expand_limits(x = us$long, y = us$lat) + coord_map() + ggtitle("USA!")
map.simple
View(us)
map.simple + geom_point(aes(-87, 25))
View(dfStates)
View(dummyDF)
test = c(1,2,3,4)
scale(test)
sd(test)
mean(test)
scale(test, center = TRUE, scale = TRUE)
scale(test)
result = scale(test)
View(result)
x = result[ , 1]
x
newTest = scale(test)[ , 1]
rm(list=ls()) # clear work space
suppressWarnings(require(ggplot2))
suppressWarnings(require(lubridate))
# get data and clean it up
dataAQ = airquality
str(dataAQ)
summary(dataAQ)
dataAQ = na.omit(dataAQ)
str(dataAQ)
summary(dataAQ)
# add year
dataAQ$Year = c(rep(1973, nrow(dataAQ)))
#dataAQ$Time = with(dataAQ, ISOdate(dataAQ$Year, dataAQ$Month, dataAQ$Day))
dataAQ$Time = ISOdate(dataAQ$Year, dataAQ$Month, dataAQ$Day)
# mutating data to fit heat map
# filtering data so that the values Ozone, Temp, Wind, and Solar are categories
# Going to make the data fit the graph I need to create
OzoneDf = dataAQ[ , c(1,5,6,7,8)]
OzoneDf$Category = c(rep("Ozone", 111))
newColNames = colnames(OzoneDf) # col names
newColNames[1] = "Value"
colnames(OzoneDf) = newColNames # Standardize columns across dfs
OzoneDf$Value = OzoneDf$Value/max(dataAQ$Ozone) # convert to percent
OzoneDf$Zscore = scale(OzoneDf$Value)[ , 1]
View(OzoneDf)
# repeat process for each value
SolarDf = dataAQ[ , c(2,5,6,7,8)]
SolarDf$Category = c(rep("Solar.R", 111))
colnames(SolarDf) = newColNames
SolarDf$Value = SolarDf$Value/max(dataAQ$Solar.R)
SolarDf$Zscore = scale(SolarDf$Value)[ , 1]
WindDf$Zscore = scale(WindDf$Value)[ , 1]
WindDf = dataAQ[ , c(3,5,6,7,8)]
WindDf$Category = c(rep("Wind", 111))
colnames(WindDf) = newColNames
WindDf$Value = WindDf$Value/max(dataAQ$Wind)
WindDf$Zscore = scale(WindDf$Value)[ , 1]
TempDf$Zscore = scale(TempDf$Value)[ , 1]
TempDf = dataAQ[ , c(4,5,6,7,8)]
TempDf$Category = c(rep("Temp", 111))
colnames(TempDf) = newColNames
TempDf$Value = TempDf$Value/max(dataAQ$Temp)
TempDf$Zscore = scale(TempDf$Value)[ , 1]
newDataAQ = rbind(OzoneDf, SolarDf, WindDf, TempDf) # combine all into one df
View(newDataAQ)
# plot heat map
ggplot(newDataAQ, aes(Day, Category)) + geom_tile(aes(fill = Value)) +
facet_grid(Year ~ Month) +
#scale_fill_gradientn(colours = heat.colors(500))
scale_fill_gradient(low = "yellow", high = "red")
# plot heat map 2 z scores
ggplot(newDataAQ, aes(Day, Category)) + geom_tile(aes(fill = Zscore)) +
facet_grid(Year ~ Month) +
#scale_fill_gradientn(colours = heat.colors(500))
scale_fill_gradient(low = "yellow", high = "red")
readStates = function() {
# read from url
states = read.csv(url("http://www2.census.gov/programs-surveys/popest/tables/2010-2011/state/totals/nst-est2011-01.csv"))
states = states[ , colSums(is.na(states)) < nrow(states)] # remove na cols
states = states[complete.cases(states),] # remove na rows
colnames(states) = c('stateName', 'base2010', 'base2011', 'Jul2010', 'Jul2011') # name cols
states = states[9:59 , ] # Only want 50 states plus DC... FU Puerto Rico
# turning those factors into numeric
states$base2010 = as.numeric(gsub(",","",states$base2010))
states$base2011 = as.numeric(gsub(",","",states$base2011))
states$Jul2010 = as.numeric(gsub(",","",states$Jul2010))
states$Jul2011 = as.numeric(gsub(",","",states$Jul2011))
return (states)
}
test = readStates()
test
View(test)
gdata
state
state
x = state
state.name
install.packages("gdata")
?gdata
getwd()
rm(list=ls()) # clear work space
getwd()
setwd("C:/Users/dvjr2/Documents")
library(Rcmdr)
summary(loanData)
View(loanData)
summary(GLM.1)
exp(coef(GLM.1))  # Exponentiated coefficients ("odds ratios")
summary(GLM.1)
exp(coef(GLM.1))  # Exponentiated coefficients ("odds ratios")
summary(GLM.3)
exp(coef(GLM.3))  # Exponentiated coefficients ("odds ratios")
GLM.4 <- glm(PersonalLoan ~  Education + Family + Income  + SecuritiesAccount + Online  + CDAccount + CreditCard, family=binomial(logit), data=loanData)
summary(GLM.4)
exp(coef(GLM.4))  # Exponentiated coefficients ("odds ratios")
summary(GLM.4)
GLM.1a <- glm(PersonalLoan ~ Age + Education + Family + Income + Mortgage,
family=binomial(probit), data=loanData)
summary(GLM.1a)
GLM.3a <- glm(PersonalLoan ~ Age + Education + Family + Income + Mortgage +
SecuritiesAccount + Online + Experience + CDAccount + CreditCard,
family=binomial(logit), data=loanData)
summary(GLM.3a)
GLM.4a <- glm(PersonalLoan ~ Education + Family + Income + SecuritiesAccount + Online + CDAccount + CreditCard,
family=binomial(probit), data=loanData)
summary(GLM.4a)
rm(list=ls())
library(Rcmdr)
logit_001 <- glm(PersonalLoan ~ Age + Education + Family + Income + Mortgage,
family=binomial(logit), data=loanData)
summary(logit_001)
exp(coef(logit_001))  # Exponentiated coefficients ("odds ratios")
probit_001 <- glm(PersonalLoan ~ Age + Education + Family + Income + Mortgage,
family=binomial(probit), data=loanData)
loanData <-
read.table("C:/Users/dvjr2/Google Drive/Documents/Syracuse/SCM_651/HW/scm651_homework_4_universal_bank.csv",
header=TRUE, sep=",", na.strings="NA", dec=".", strip.white=TRUE)
summary(loanData)
logit_001 <- glm(PersonalLoan ~ Age + Education + Family + Income + Mortgage,
family=binomial(logit), data=loanData)
summary(logit_001)
exp(coef(logit_001))  # Exponentiated coefficients ("odds ratios")
probit_001 <- glm(PersonalLoan ~ Age + Education + Family + Income + Mortgage,
family=binomial(probit), data=loanData)
summary(probit_001)
logit_002 <- glm(PersonalLoan ~ Age + Education + Family + Income + Mortgage +
SecuritiesAccount + Online + Experience + CDAccount + CreditCard,
family=binomial(logit), data=loanData)
summary(logit_002)
exp(coef(logit_002))  # Exponentiated coefficients ("odds ratios")
probit_002 <- glm(PersonalLoan ~ Age + Education + Family + Income + Mortgage +
SecuritiesAccount + Online + Experience + CDAccount + CreditCard,
family=binomial(logit), data=loanData)
summary(probit_002)
logit_003 <- glm(PersonalLoan ~  Education + Family + Income  + SecuritiesAccount + Online  + CDAccount + CreditCard, family=binomial(logit), data=loanData)
summary(logit_003)
exp(coef(logit_003))  # Exponentiated coefficients ("odds ratios")
probit_003 <- glm(PersonalLoan ~ Education + Family + Income + SecuritiesAccount + Online + CDAccount + CreditCard,
family=binomial(probit), data=loanData)
summary(probit_003)
summary(logit_001)
summary(logit_002)
summary(logit_002)
summary(logit_003)
summary(logit_001)
max(loanData$Income)
min(loanData$Income)
probit_002 <- glm(PersonalLoan ~ Age + Education + Family + Income + Mortgage +
SecuritiesAccount + Online + Experience + CDAccount + CreditCard,
family=binomial(probit), data=loanData)
probit_003 <- glm(PersonalLoan ~ Education + Family + Income + SecuritiesAccount + Online + CDAccount + CreditCard,
family=binomial(probit), data=loanData)
logit_003 <- glm(PersonalLoan ~  Education + Family + Income  + SecuritiesAccount + Online  + CDAccount + CreditCard, family=binomial(logit), data=loanData)
exp(coef(logit_003))  # Exponentiated coefficients ("odds ratios")
summary(logit_003)
View(loanData)
summary(loanData)
str(loanData)
View(loanData)
summary(logit_003)
test = loanData[loanData$PersonalLoan == 1, ]
View(test)
test1 = loanData[loanData$PersonalLoan == 0, ]
View(test1)
View(test)
summary(probit_003)
summary(GLM.21)
summary(GLM.22)
rm(list=ls())
install.packages("neuralnet")
library(neuralnet)
loanData <-
read.table("C:/Users/dvjr2/Google Drive/Documents/Syracuse/SCM_651/HW/scm651_homework_4_universal_bank.csv",
header=TRUE, sep=",", na.strings="NA", dec=".", strip.white=TRUE)
summary(loanData)
str(loanData)
GLM.21 <- glm(PersonalLoan ~ Income + CCAvg + Education + Income * CCAvg + CDAccount, family=binomial(logit), data=loanData)
summary(GLM.21)
exp(coef(GLM.21))  # Exponentiated coefficients ("odds ratios")
GLM.22 <- glm(PersonalLoan ~ Income + CCAvg + Education + Income * CCAvg + CDAccount, family=binomial(probit), data=loanData)
summary(GLM.22)
View(loanData)
result <- neuralnet(PersonalLoan ~ Income+CCAvg,loanData, hidden=2, lifesign='minimal', linear.output=FALSE, threshold=0.1)
View(result)
plot(result,rep='best')
result$result.matrix
rm(list=ls())
gpa <- c(3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 4.7)
age <- c(21, 22, 23, 24, 25, 26, 27)
wt <- c(151, 142, 133, 164, 165, 166, 167)
df <- data.frame(gpa, age, wt)
df[2, 3]
df1 = df[-nrow(df),]
View(df1)
View(df)
View(df)
gpa <- c(3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 4.7)
age <- c(21, 22, 23, 24, 25, 26, 27)
wt <- c(151, 142, 133, 164, 165, 166, 167)
df <- data.frame(gpa, age, wt)
df1 = df[,-6:-7]
gpa <- c(3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 4.7)
age <- c(21, 22, 23, 24, 25, 26, 27)
wt <- c(151, 142, 133, 164, 165, 166, 167)
df <- data.frame(gpa, age, wt)
df[2, 3]
df1 = df[,-6:-7]
df1 = df[,c(-2,-3)]
gpa <- c(3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 4.7)
age <- c(21, 22, 23, 24, 25, 26, 27)
wt <- c(151, 142, 133, 164, 165, 166, 167)
df <- data.frame(gpa, age, wt)
df[2, 3]
df1 = df[,c(-2,-3)]
df1 = df[ ,]
df1 = df[ ,-2:-3]
df1 = df[ ,-1]
df1 = df[ ,c(-2,-3)]
df <- data.frame(gpa, age, wt)
df$weightPerAge = df$wt/df$age
vec = c(1,2,3)
vec = vec -4
mean(vec)
vec = c(1,2,3)
vec = c(1,2,3)
vec -4
mean(vec)
quantile(vec)
smallData = c(1,2,3,4,5)
sample(smallData, 6)
sample(smallData, 1)
replicate(sample(smallData, 1), 6)
sample(smallData, 6. replace = TRUE)
sample(smallData, 6, replace = TRUE)
mean(replicate(1000,mean(sample(smallData,size=5,replace=FALSE))))
mean(replicate(1000,mean(sample(smallData,size=5,replace=FALSE))))
mean(replicate(1000,mean(sample(smallData,size=5,replace=FALSE))))
mean(replicate(1000,mean(sample(smallData,size=5,replace=FALSE))))
testData = c(1:10)
ggplot2::ggplot(testData ) +  geom_histogram()
plot(testData)
ggplot2::ggplot(testData aes(testData)) +  geom_histogram()
ggplot2::ggplot(testData, aes(testData)) +  geom_histogram()
library(ggplot2)
ggplot(testData, aes(testData)) +  geom_histogram()
hist(testData)
x = replicate(sample(testData, 1), 50)
hist(x)
replicate(sample(smallData, 1), 6)
sample(smallData, 6, replace = TRUE)
hist(sample(smallData, 6, replace = TRUE))
hist(sample(testData, 50, replace = TRUE))
myFamilyNames <- c("Dad","Mom","Sis","Bro","Dog")
myFamilyAges <- c(43, 42, 12, 8, 5)
myFamilyGenders <- c("Male","Female","Female","Male","Female")
myFamilyWeights <- c(188,136,83,61,44)
myFamily <- data.frame(myFamilyNames, +
myFamilyAges, myFamilyGenders, myFamilyWeights)
myFamily$myFamilyNames <-c(myFamilyNames, "Cat")
myFamilyNames <-c(myFamilyNames, "Mouse")
myFamilyNames <- c("Dad","Mom","Sis","Bro","Dog")
myFamilyAges <- c(43, 42, 12, 8, 5)
myFamilyGenders <- c("Male","Female","Female","Male","Female")
myFamilyWeights <- c(188,136,83,61,44)
myFamily <- data.frame(myFamilyNames, ,myFamilyAges, myFamilyGenders, myFamilyWeights)
myFamily$myFamilyNames <-c(myFamilyNames, "Cat")
myFamilyNames <- c("Dad","Mom","Sis","Bro","Dog")
myFamilyAges <- c(43, 42, 12, 8, 5)
myFamilyGenders <- c("Male","Female","Female","Male","Female")
myFamilyWeights <- c(188,136,83,61,44)
myFamily <- data.frame(myFamilyNames ,myFamilyAges, myFamilyGenders, myFamilyWeights)
myFamily$myFamilyNames <-c(myFamilyNames, "Cat")
myFamilyNames <-c(myFamilyNames, "Mouse")
myFamilyNames <- c("Dad","Mom","Sis","Bro","Dog")
myFamilyAges <- c(43, 42, 12, 8, 5)
myFamilyGenders <- c("Male","Female","Female","Male","Female")
myFamilyWeights <- c(188,136,83,61,44)
myFamily <- data.frame(myFamilyNames ,myFamilyAges, myFamilyGenders, myFamilyWeights)
myFamily$myFamilyNames <-c(myFamilyNames, "Cat")
myFamilyNames <-c(myFamilyNames, "Mouse")
View(df)
View(myFamily)
myFirstF = function(x) {
return mean(x)
}
myFirstF = function(x) {
return mean(x)
}
myFirstF = function(x) {
}
myFirstF = function(x) {
return (mean(x))
}
myFirstF(testData)
suppressWarnings(require(ggplot2))
suppressWarnings(require(maps))
suppressWarnings(require(mapproj))
suppressWarnings(require(openxlsx))
suppressWarnings(require(zipcode))
suppressWarnings(require(openintro))
us = map_data("state") # get map data
Cities <- c(“Syracuse NY”, “Newark, DE”)
Rating <- c( 0.8, 0,3)
dumbQues = cbind(Cities, Rating)
Cities <- c(“Syracuse NY”, “Newark, DE”)
Rating <- c( 0.8, 0,3)
dumbQues = cbind(Cities, Rating)
dumbQues = cbind(Cities, Rating)
Cities <- c(“Syracuse NY”, “Newark, DE”)
Cities = c("Syracuse NY", "Newark, DE")
Rating <- c( 0.8, 0,3)
dumbQues = cbind(Cities, Rating)
Rating <- c( 0.8, 0.3)
dumbQues = cbind(Cities, Rating)
us = map_data("state") # get map data
ggplot(dumbQues, aes(map_id = states)) +
geom_map(map = us, color = "black") +
expand_limits(x = us$long, y = us$lat) +
coord_map() + ggtitle("USA! Median Income")
dumbQues = as.data.frame(Cities, Rating)
dumbQues = data.frame(Cities, Rating)
ggplot(dumbQues, aes(map_id = states)) +
geom_map(map = us, color = "black") +
expand_limits(x = us$long, y = us$lat) +
coord_map() + ggtitle("USA! Median Income")
ggplot(dumbQues, aes(map_id = state)) +
geom_map(map = us, color = "black") +
expand_limits(x = us$long, y = us$lat) +
coord_map() + ggtitle("USA! Median Income")
rm(list=ls())
library(Rcmdr)
loanData <-
read.table("C:/Users/dvjr2/Google Drive/Documents/Syracuse/SCM_651/HW/scm651_homework_4_universal_bank.csv",
header=TRUE, sep=",", na.strings="NA", dec=".", strip.white=TRUE)
summary(loanData)
logit_001 <- glm(PersonalLoan ~ Age + Education + Family + Income + Mortgage,
family=binomial(logit), data=loanData)
summary(logit_001)
exp(coef(logit_001))  # Exponentiated coefficients ("odds ratios")
probit_001 <- glm(PersonalLoan ~ Age + Education + Family + Income + Mortgage,
family=binomial(probit), data=loanData)
summary(probit_001)
logit_002 <- glm(PersonalLoan ~ Age + Education + Family + Income + Mortgage +
SecuritiesAccount + Online + Experience + CDAccount + CreditCard,
family=binomial(logit), data=loanData)
summary(logit_002)
rm(list=ls())
library(Rcmdr)
library(neuralnet)
loanData <-
read.table("C:/Users/dvjr2/Google Drive/Documents/Syracuse/SCM_651/HW/scm651_homework_4_universal_bank.csv",
header=TRUE, sep=",", na.strings="NA", dec=".", strip.white=TRUE)
summary(loanData)
str(loanData)
GLM.21 <- glm(PersonalLoan ~ Income + CCAvg + Education + Income * CCAvg + CDAccount, family=binomial(logit), data=loanData)
summary(GLM.21)
exp(coef(GLM.21))  # Exponentiated coefficients ("odds ratios")
GLM.22 <- glm(PersonalLoan ~ Income + CCAvg + Education + Income * CCAvg + CDAccount, family=binomial(probit), data=loanData)
summary(GLM.22)
result <- neuralnet(PersonalLoan ~ Income+CCAvg,loanData, hidden=2, lifesign='minimal', linear.output=FALSE, threshold=0.1)
plot(result,rep='best')
result$result.matrix
plot(result,rep='best')
result01 <- neuralnet(PersonalLoan ~ Income + CCAvg + Education + Income * CCAvg + CDAccount,loanData, hidden=2, lifesign='minimal', linear.output=FALSE, threshold=0.1)
result01 <- neuralnet(PersonalLoan ~ Income + CCAvg + Education  + CDAccount,loanData, hidden=2, lifesign='minimal', linear.output=FALSE, threshold=0.1)
plot(result01,rep='best')
plot(result01,rep='best')
result01$result.matrix
plot(result,rep='best')
test <- glm(PersonalLoan ~ Income + CCAvg, family=binomial(logit), data=loanData)
summary(test)
test <- glm(PersonalLoan ~ Income + Education, family=binomial(logit), data=loanData)
summary(test)
result <- neuralnet(PersonalLoan ~ Income+Education,loanData, hidden=2, lifesign='minimal', linear.output=FALSE, threshold=0.1)
plot(result,rep='best')
result$result.matrix
?strrep
setwd("C:/Users/dvjr2/Google Drive/Documents/Syracuse/IST_687/Project/")
filePath = "clean_power_lifting.csv" # cleaned data - yay Katie!
# read data and take a look
powerLiftingOG <- read.csv(file = filePath, header=TRUE, sep=",", stringsAsFactors = FALSE)
str(powerLiftingOG)
summary(powerLiftingOG)
powerLiftingOG$Sex = as.factor(powerLiftingOG$Sex) # Make Sex a factor for predicting
powerLifting = powerLiftingOG[ , c(-1,-2,-3, -5,-6, -8, -12, -13)] # get rid of unwanted cols
powerLifting = na.omit(powerLifting) # clear NAs to run model
powerLifting = powerLifting[sample(nrow(powerLifting)), ] # randomize
trngData = powerLifting[1:ceiling(nrow(powerLifting)*.7) , ] # trng data 70% of original data
testData = powerLifting[(ceiling(nrow(powerLifting)*.7)+1):nrow(powerLifting), ] # test data
############################################################################################################
#                                             Random Forest
############################################################################################################
modelRF = randomForest(trngData[ , -1], trngData[ , 1]) # independent, dependent
summary(modelRF)
round(importance(modelRF), 2) # importance of variables, high is better
# make predictions
results = predict(modelRF, testData[ ,  -1])
# look at results w/ confusion matrix
table(results)
table(testData$Sex)
matrix = table(results, testData$Sex)
matrix
# male vs female accuracy
print(paste('Female Predict Accuracy:', matrix[1,1]/sum(testData$Sex == "F")))
print(paste('Male Predict Accuracy:', matrix[2,2]/sum(testData$Sex == "M")))
# Overall accuracy
print(paste('Overall Accuracy: ', (matrix[1,1] + matrix[2,2])/length(testData$Sex )))
############################################################################################################
#                                           Linear Model
############################################################################################################
# change F/M to 1/0, LM seems to work better this way
trngData$Sex = ifelse(trngData$Sex == 'F', 1, 0)
testData$Sex = ifelse(testData$Sex == 'F', 1, 0)
# Lm with same variables used in randomForest()
modelGLM = glm(Sex ~ BodyweightKg + BestSquatKg + BestBenchKg + BestDeadliftKg, data = trngData, family = "binomial")
summary(modelGLM) # all variables are significant
modelGLM
modelGLM$
d
modelGLM$fitted.values
modelGLM$residuals
modelGLM$coefficients
modelGLM$qr
modelGLM$R
